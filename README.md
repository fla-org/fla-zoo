<div align="center">

# FLA-Zoo: Flash-Linear-Attention models beyond language

</div>
<div align="center">
This repository implements a collection of Flash-Linear-Attention models that extend beyond language, supporting vision, video, and more.
</div>

<div align="center">
  <br/>
  <img width="400" alt="diagram" src="assets/flazoo.png">
  <!-- <br/>
  <em>[ai generated image with modifications]</em> -->
</div>
<br/>

* [News](#news)
* [Features](#features)
* [Installation](#installation)
* [TODO](#todo)
<!-- * [Citation](#citation) -->

## News

- **$\texttt{[2025-01-25]}$:** This repo is created with vision models.

## Features

- **`vision`:** `fla-zoo` currently supports vision models. A simple documentation is in [here](docs/vision/vision.md).

## Installation

Requirements:
- All the dependencies shown [here](https://github.com/fla-org/flash-linear-attention?tab=readme-ov-file#installation)
- [torchvision](https://github.com/pytorch/vision)

As an actively developed repo, no released packages are provided.

## TODO

- [x] Write documentation for vision models.
- [ ] Release training scripts for vision models.
